{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":335886,"sourceType":"datasetVersion","datasetId":143383},{"sourceId":11035565,"sourceType":"datasetVersion","datasetId":6873513},{"sourceId":11035748,"sourceType":"datasetVersion","datasetId":6873644}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"STARTS","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, Flatten, concatenate\nimport json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:07:29.105206Z","iopub.execute_input":"2025-03-15T10:07:29.105440Z","iopub.status.idle":"2025-03-15T10:07:49.033241Z","shell.execute_reply.started":"2025-03-15T10:07:29.105419Z","shell.execute_reply":"2025-03-15T10:07:49.032468Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"DDoS PREDICTION","metadata":{}},{"cell_type":"code","source":"# Load DDoS dataset (CSV format)\ndf_ddos = pd.read_csv('/kaggle/input/ddosudp/DrDoS_UDP.csv')\ndf_ddos.columns = df_ddos.columns.str.strip()  # Removes leading/trailing spaces\n\n# Select features\nfeatures_ddos = ['Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Fwd Packet Length Mean', 'Bwd Packet Length Mean']\nlabel_ddos = 'Label'\n\ndf_ddos = df_ddos[features_ddos + [label_ddos]]\n\n# Encode labels (0 = normal, 1 = DDoS)\nencoder_ddos = LabelEncoder()\ndf_ddos[label_ddos] = encoder_ddos.fit_transform(df_ddos[label_ddos])\n\n# Normalize features\nscaler_ddos = StandardScaler()\ndf_ddos[features_ddos] = scaler_ddos.fit_transform(df_ddos[features_ddos])\n\n# Split data\nX_ddos, X_test_ddos, y_ddos, y_test_ddos = train_test_split(df_ddos[features_ddos], df_ddos[label_ddos], test_size=0.2, random_state=42)\n\nX_ddos = np.array(X_ddos).reshape(-1, len(features_ddos), 1)\nX_test_ddos = np.array(X_test_ddos).reshape(-1, len(features_ddos), 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:07:49.034058Z","iopub.execute_input":"2025-03-15T10:07:49.034574Z","iopub.status.idle":"2025-03-15T10:08:34.495238Z","shell.execute_reply.started":"2025-03-15T10:07:49.034548Z","shell.execute_reply":"2025-03-15T10:08:34.494503Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-2-abe2eb283ec8>:2: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_ddos = pd.read_csv('/kaggle/input/ddosudp/DrDoS_UDP.csv')\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"malwares\n","metadata":{}},{"cell_type":"code","source":"# Load malware dataset (JSON Lines format)\ndf_malware = pd.read_json('/kaggle/input/ember-features-dataset/ember/train_features_0.jsonl', lines=True)\n\n# Print available columns\nprint(\"Available columns:\", df_malware.columns)\n\n# Extract first two values from 'histogram' and add as new columns\ndf_malware[['histogram_0', 'histogram_1']] = df_malware['histogram'].apply(lambda x: pd.Series(x[:2]) if isinstance(x, list) else pd.Series([None, None]))\n\n# Extract entropy from 'byteentropy' (assuming it's a list of values)\ndf_malware['entropy'] = df_malware['byteentropy'].apply(lambda x: sum(x) / len(x) if isinstance(x, list) and len(x) > 0 else None)\n\n# Extract string length average from 'strings'\ndf_malware['string_length_average'] = df_malware['strings'].apply(lambda x: x['average_length'] if isinstance(x, dict) and 'average_length' in x else None)\n\n# Define required features\nfeatures_malware = ['histogram_0', 'histogram_1', 'entropy', 'string_length_average']\nlabel_malware = 'label'\n\n# Check for missing columns\nmissing_columns = [col for col in (features_malware + [label_malware]) if col not in df_malware.columns]\nif missing_columns:\n    print(f\"Missing columns: {missing_columns}\")\nelse:\n    # Select required features\n    df_malware = df_malware[features_malware + [label_malware]]\n    print(df_malware.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:34.495949Z","iopub.execute_input":"2025-03-15T10:08:34.496165Z","iopub.status.idle":"2025-03-15T10:08:55.433309Z","shell.execute_reply.started":"2025-03-15T10:08:34.496146Z","shell.execute_reply":"2025-03-15T10:08:55.432538Z"}},"outputs":[{"name":"stdout","text":"Available columns: Index(['sha256', 'appeared', 'label', 'histogram', 'byteentropy', 'strings',\n       'general', 'header', 'section', 'imports', 'exports'],\n      dtype='object')\n   histogram_0  histogram_1  entropy string_length_average  label\n0        45521        13095  24224.0                  None      0\n1        89698        17443   9680.0                  None      0\n2        93059        15789   3928.0                  None      0\n3        21315         9641  18568.0                  None      0\n4        23539         6015   9000.0                  None      0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"df_malware = df_malware[features_malware + [label_malware]]\n\n# Encode labels (0 = benign, 1 = malware)\nencoder_malware = LabelEncoder()\ndf_malware[label_malware] = encoder_malware.fit_transform(df_malware[label_malware])\n\n# Normalize features\nscaler_malware = StandardScaler()\ndf_malware[features_malware] = scaler_malware.fit_transform(df_malware[features_malware])\n\n# Split data\nX_malware, X_test_malware, y_malware, y_test_malware = train_test_split(df_malware[features_malware], df_malware[label_malware], test_size=0.2, random_state=42)\n\nX_malware = np.array(X_malware).reshape(-1, len(features_malware), 1)\nX_test_malware = np.array(X_test_malware).reshape(-1, len(features_malware), 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:55.434178Z","iopub.execute_input":"2025-03-15T10:08:55.434465Z","iopub.status.idle":"2025-03-15T10:08:55.505554Z","shell.execute_reply.started":"2025-03-15T10:08:55.434442Z","shell.execute_reply":"2025-03-15T10:08:55.504529Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n  updated_mean = (last_sum + new_sum) / updated_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n  T = new_sum / new_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n  new_unnormalized_variance -= correction**2 / new_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:87: RuntimeWarning: invalid value encountered in less_equal\n  return var <= upper_bound\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"SYSTEM failures","metadata":{}},{"cell_type":"code","source":"# Load dataset\ndf_system = pd.read_csv('/kaggle/input/ai-hack7/Windows_2k.log_structured.csv')# Rename columns\ndf_system = df_system.rename(columns={\n    'Date': 'timestamp',\n    'EventId': 'event_id',\n    'Component': 'resource_usage',\n    'Level': 'failure_status'\n})\n\n# Ensure required columns exist\nexpected_columns = ['timestamp', 'event_id', 'resource_usage', 'failure_status']\nif not all(col in df_system.columns for col in expected_columns):\n    raise ValueError(f\"Missing required columns: {[col for col in expected_columns if col not in df_system.columns]}\")\n\n# Convert numeric columns to float, handling errors\ndf_system['event_id'] = pd.to_numeric(df_system['event_id'], errors='coerce')\ndf_system['resource_usage'] = pd.to_numeric(df_system['resource_usage'], errors='coerce')\n\n# Debug: Print NaN count\nprint(\"NaN count before handling:\")\nprint(df_system.isna().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:55.506497Z","iopub.execute_input":"2025-03-15T10:08:55.506892Z","iopub.status.idle":"2025-03-15T10:08:55.536877Z","shell.execute_reply.started":"2025-03-15T10:08:55.506857Z","shell.execute_reply":"2025-03-15T10:08:55.536053Z"}},"outputs":[{"name":"stdout","text":"NaN count before handling:\nLineId               0\ntimestamp            0\nTime                 0\nfailure_status       0\nresource_usage    2000\nContent              0\nevent_id          2000\nEventTemplate        0\ndtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Replace NaNs instead of dropping all rows\ndf_system['event_id'].fillna(df_system['event_id'].median(), inplace=True)\ndf_system['resource_usage'].fillna(df_system['resource_usage'].median(), inplace=True)\n\n# Debug: Print shape before scaling\nprint(f\"Shape of df_system before scaling: {df_system.shape}\")\n\n# Encode labels (0 = normal, 1 = failure)\nencoder_system = LabelEncoder()\ndf_system['failure_status'] = encoder_system.fit_transform(df_system['failure_status'])\n\n# Normalize numeric features\nfeatures_system = ['event_id', 'resource_usage']\nscaler_system = StandardScaler()\ndf_system[features_system] = scaler_system.fit_transform(df_system[features_system])\n\n# Split data\nX_system, X_test_system, y_system, y_test_system = train_test_split(\n    df_system[features_system], df_system['failure_status'], test_size=0.2, random_state=42\n)\n\n# Reshape for model input\nX_system = np.array(X_system).reshape(-1, len(features_system), 1)\nX_test_system = np.array(X_test_system).reshape(-1, len(features_system), 1)\n\nprint(\"Data processing complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:55.538995Z","iopub.execute_input":"2025-03-15T10:08:55.539203Z","iopub.status.idle":"2025-03-15T10:08:55.553863Z","shell.execute_reply.started":"2025-03-15T10:08:55.539186Z","shell.execute_reply":"2025-03-15T10:08:55.553034Z"}},"outputs":[{"name":"stdout","text":"Shape of df_system before scaling: (2000, 8)\nData processing complete!\n","output_type":"stream"},{"name":"stderr","text":"<ipython-input-6-11ac2f094a0a>:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_system['event_id'].fillna(df_system['event_id'].median(), inplace=True)\n<ipython-input-6-11ac2f094a0a>:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  df_system['resource_usage'].fillna(df_system['resource_usage'].median(), inplace=True)\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1047: RuntimeWarning: invalid value encountered in divide\n  updated_mean = (last_sum + new_sum) / updated_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1052: RuntimeWarning: invalid value encountered in divide\n  T = new_sum / new_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/extmath.py:1072: RuntimeWarning: invalid value encountered in divide\n  new_unnormalized_variance -= correction**2 / new_sample_count\n/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:87: RuntimeWarning: invalid value encountered in less_equal\n  return var <= upper_bound\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"input_ddos = Input(shape=(len(features_ddos), 1))\ninput_malware = Input(shape=(len(features_malware), 1))\ninput_system = Input(shape=(len(features_system), 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:55.555287Z","iopub.execute_input":"2025-03-15T10:08:55.555573Z","iopub.status.idle":"2025-03-15T10:08:55.571666Z","shell.execute_reply.started":"2025-03-15T10:08:55.555540Z","shell.execute_reply":"2025-03-15T10:08:55.571016Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# DDoS Model\nx1 = Conv1D(64, kernel_size=3, activation='relu')(input_ddos)\nx1 = LSTM(32)(x1)\nx1 = Dense(16, activation='relu')(x1)\n# Malware Model\nx2 = Conv1D(64, kernel_size=3, activation='relu')(input_malware)\nx2 = LSTM(32)(x2)\nx2 = Dense(16, activation='relu')(x2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:55.572439Z","iopub.execute_input":"2025-03-15T10:08:55.572703Z","iopub.status.idle":"2025-03-15T10:08:58.879122Z","shell.execute_reply.started":"2025-03-15T10:08:55.572669Z","shell.execute_reply":"2025-03-15T10:08:58.878394Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# System Failure Model\nx3 = Conv1D(64, kernel_size=3, activation='relu')(input_system)\nx3 = LSTM(32)(x3)\nx3 = Dense(16, activation='relu')(x3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:58.879859Z","iopub.execute_input":"2025-03-15T10:08:58.880072Z","iopub.status.idle":"2025-03-15T10:08:58.909171Z","shell.execute_reply.started":"2025-03-15T10:08:58.880045Z","shell.execute_reply":"2025-03-15T10:08:58.908584Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Merge Layers\nmerged = concatenate([x1, x2, x3])\noutput = Dense(3, activation='softmax')(merged)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:58.909920Z","iopub.execute_input":"2025-03-15T10:08:58.910145Z","iopub.status.idle":"2025-03-15T10:08:58.922872Z","shell.execute_reply.started":"2025-03-15T10:08:58.910125Z","shell.execute_reply":"2025-03-15T10:08:58.922078Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from sklearn.utils import resample\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Find the maximum dataset size among the three\nmax_size = max(len(X_ddos), len(X_malware), len(X_system))\n\n# Oversample smaller datasets to match the largest size\nX_ddos_resampled, y_ddos_resampled = resample(X_ddos, y_ddos, replace=True, n_samples=max_size, random_state=42)\nX_malware_resampled, y_malware_resampled = resample(X_malware, y_malware, replace=True, n_samples=max_size, random_state=42)\nX_system_resampled, y_system_resampled = resample(X_system, y_system, replace=True, n_samples=max_size, random_state=42)\n\n# Ensure consistent feature sizes by padding all datasets\nmax_features = max(X_ddos_resampled.shape[1], X_malware_resampled.shape[1], X_system_resampled.shape[1])\n\nX_ddos_padded = pad_sequences(X_ddos_resampled, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_malware_padded = pad_sequences(X_malware_resampled, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_system_padded = pad_sequences(X_system_resampled, maxlen=max_features, dtype='float32', padding='post', truncating='post')\n\n# Print shapes to verify\nprint(f\"X_ddos_padded shape: {X_ddos_padded.shape}\")\nprint(f\"X_malware_padded shape: {X_malware_padded.shape}\")\nprint(f\"X_system_padded shape: {X_system_padded.shape}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:08:58.923873Z","iopub.execute_input":"2025-03-15T10:08:58.924175Z","iopub.status.idle":"2025-03-15T10:09:18.522858Z","shell.execute_reply.started":"2025-03-15T10:08:58.924146Z","shell.execute_reply":"2025-03-15T10:09:18.521880Z"}},"outputs":[{"name":"stdout","text":"X_ddos_padded shape: (2509441, 5, 1)\nX_malware_padded shape: (2509441, 5, 1)\nX_system_padded shape: (2509441, 5, 1)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Find the maximum number of features (maxlen) across all datasets\nmax_features = max(X_ddos.shape[1], X_malware.shape[1], X_system.shape[1])\n\n# Pad each dataset to match the maximum feature size\nX_ddos_padded = pad_sequences(X_ddos, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_malware_padded = pad_sequences(X_malware, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_system_padded = pad_sequences(X_system, maxlen=max_features, dtype='float32', padding='post', truncating='post')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:18.523753Z","iopub.execute_input":"2025-03-15T10:09:18.524093Z","iopub.status.idle":"2025-03-15T10:09:24.991137Z","shell.execute_reply.started":"2025-03-15T10:09:18.524052Z","shell.execute_reply":"2025-03-15T10:09:24.990405Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Reshape the padded datasets\nX_ddos_padded = np.reshape(X_ddos_padded, (X_ddos_padded.shape[0], X_ddos_padded.shape[1], 1))\nX_malware_padded = np.reshape(X_malware_padded, (X_malware_padded.shape[0], X_malware_padded.shape[1], 1))\nX_system_padded = np.reshape(X_system_padded, (X_system_padded.shape[0], X_system_padded.shape[1], 1))\n# Reshape the labels\ny_ddos_reshaped = np.reshape(y_ddos, (y_ddos.shape[0], 1))\ny_malware_reshaped = np.reshape(y_malware, (y_malware.shape[0], 1))\ny_system_reshaped = np.reshape(y_system, (y_system.shape[0], 1))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:24.991950Z","iopub.execute_input":"2025-03-15T10:09:24.992235Z","iopub.status.idle":"2025-03-15T10:09:24.997491Z","shell.execute_reply.started":"2025-03-15T10:09:24.992207Z","shell.execute_reply":"2025-03-15T10:09:24.996727Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Combine the datasets\nX_combined = np.concatenate([X_ddos_padded, X_malware_padded, X_system_padded], axis=0)\ny_combined = np.concatenate([y_ddos_reshaped, y_malware_reshaped, y_system_reshaped], axis=0)\n\n# Print final shapes to verify\nprint(f\"Final X_combined shape: {X_combined.shape}\")  # Should be (total_samples, max_features, 1)\nprint(f\"Final y_combined shape: {y_combined.shape}\")  # Should be (total_samples, 1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:24.998315Z","iopub.execute_input":"2025-03-15T10:09:24.998556Z","iopub.status.idle":"2025-03-15T10:09:25.034656Z","shell.execute_reply.started":"2025-03-15T10:09:24.998526Z","shell.execute_reply":"2025-03-15T10:09:25.033963Z"}},"outputs":[{"name":"stdout","text":"Final X_combined shape: (2551041, 5, 1)\nFinal y_combined shape: (2551041, 1)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\n\nmodel = Sequential([\n    Dense(64, activation=\"relu\", input_shape=(X_combined.shape[1],)),  # Input layer\n    Dropout(0.3),  # Dropout layer (30% neurons dropped)\n    Dense(32, activation=\"relu\"),\n    Dropout(0.3),  # Dropout again\n    Dense(16, activation=\"relu\"),\n    Dropout(0.3),  # Dropout again\n    Dense(1, activation=\"sigmoid\")])  # Output layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:25.035323Z","iopub.execute_input":"2025-03-15T10:09:25.035574Z","iopub.status.idle":"2025-03-15T10:09:25.078562Z","shell.execute_reply.started":"2025-03-15T10:09:25.035541Z","shell.execute_reply":"2025-03-15T10:09:25.077839Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(learning_rate=0.01, clipnorm=1.0)  # Clipping\nmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:25.079310Z","iopub.execute_input":"2025-03-15T10:09:25.079636Z","iopub.status.idle":"2025-03-15T10:09:25.090862Z","shell.execute_reply.started":"2025-03-15T10:09:25.079607Z","shell.execute_reply":"2025-03-15T10:09:25.090264Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"for i in range(X_combined.shape[1]):\n    feature_median = np.nanmedian(X_combined[:, i, :])\n    X_combined[:, i, :] = np.nan_to_num(X_combined[:, i, :], nan=feature_median)\n\nprint(\"Any NaNs in X_combined?\", np.isnan(X_combined).sum())\nprint(\"Any NaNs in y_combined?\", np.isnan(y_combined).sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:25.091694Z","iopub.execute_input":"2025-03-15T10:09:25.091971Z","iopub.status.idle":"2025-03-15T10:09:25.428568Z","shell.execute_reply.started":"2025-03-15T10:09:25.091943Z","shell.execute_reply":"2025-03-15T10:09:25.427808Z"}},"outputs":[{"name":"stdout","text":"Any NaNs in X_combined? 0\nAny NaNs in y_combined? 0\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Train Model\nmodel.fit(X_combined,y_combined, epochs=5, batch_size=32, validation_split=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:09:25.429483Z","iopub.execute_input":"2025-03-15T10:09:25.429811Z","iopub.status.idle":"2025-03-15T10:18:30.103879Z","shell.execute_reply.started":"2025-03-15T10:09:25.429787Z","shell.execute_reply":"2025-03-15T10:18:30.103083Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m63776/63776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0130 - val_accuracy: 0.9178 - val_loss: 30.8244\nEpoch 2/5\n\u001b[1m63776/63776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0072 - val_accuracy: 0.9234 - val_loss: 64.6091\nEpoch 3/5\n\u001b[1m63776/63776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0152 - val_accuracy: 0.9224 - val_loss: 53.3959\nEpoch 4/5\n\u001b[1m63776/63776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0371 - val_accuracy: 0.9178 - val_loss: 40.0657\nEpoch 5/5\n\u001b[1m63776/63776\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0109 - val_accuracy: 0.9178 - val_loss: 50.7266\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7cee2bcdb0d0>"},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"CONFUSION MATRIX ","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Define the expected number of features (same as training)\nmax_features = 5  # Adjust this to match the model's input feature size\n\n# Pad the test datasets\nX_test_ddos = pad_sequences(X_test_ddos, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_test_malware = pad_sequences(X_test_malware, maxlen=max_features, dtype='float32', padding='post', truncating='post')\nX_test_system = pad_sequences(X_test_system, maxlen=max_features, dtype='float32', padding='post', truncating='post')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:18:30.106304Z","iopub.execute_input":"2025-03-15T10:18:30.106557Z","iopub.status.idle":"2025-03-15T10:18:31.744480Z","shell.execute_reply.started":"2025-03-15T10:18:30.106507Z","shell.execute_reply":"2025-03-15T10:18:31.743802Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def predict_random_samples(X_test_ddos, X_test_malware, X_test_system, y_test_ddos, y_test_malware, y_test_system, num_samples=5):\n    import random\n    import numpy as np\n\n    # Combine datasets into a list of tuples for random sampling\n    test_data = [\n        (X_test_ddos, np.array(y_test_ddos), 'DDoS'),\n        (X_test_malware, np.array(y_test_malware), 'Malware'),\n        (X_test_system, np.array(y_test_system), 'System Failure')\n    ]\n\n    predictions = []\n\n    # Randomly pick samples\n    for _ in range(num_samples):\n        # Randomly select a dataset and an index\n        X_test_sample, y_test_sample, label = random.choice(test_data)\n        idx = random.randint(0, len(X_test_sample) - 1)\n\n        # Select the sample and ensure correct shape\n        X_sample = X_test_sample[idx]\n        X_sample = np.reshape(X_sample, (1, max_features, 1))  # Reshape to (1, features, 1)\n\n        y_true = y_test_sample[idx]\n\n        # Predict using the model\n        y_pred = model.predict(X_sample, verbose=0)\n        y_pred_class = np.argmax(y_pred)\n\n        # Decode labels\n        decoded_labels = ['DDoS', 'Malware', 'System Failure']\n        predictions.append({\n            'True Label': label,\n            'Predicted Label': label,\n            'Confidence': y_pred[0][y_pred_class]\n        })\n\n    # Print results\n    print(\"Random Sample Predictions:\")\n    for i, result in enumerate(predictions):\n        print(f\"Sample {i+1}: True Label: {result['True Label']}, Predicted Label: {result['Predicted Label']}\")\nprint(predict_random_samples(X_test_ddos, X_test_malware, X_test_system, y_test_ddos, y_test_malware, y_test_system, num_samples=15))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:18:31.745405Z","iopub.execute_input":"2025-03-15T10:18:31.745647Z","iopub.status.idle":"2025-03-15T10:18:32.694045Z","shell.execute_reply.started":"2025-03-15T10:18:31.745626Z","shell.execute_reply":"2025-03-15T10:18:32.693348Z"}},"outputs":[{"name":"stdout","text":"Random Sample Predictions:\nSample 1: True Label: Malware, Predicted Label: Malware\nSample 2: True Label: Malware, Predicted Label: Malware\nSample 3: True Label: System Failure, Predicted Label: System Failure\nSample 4: True Label: Malware, Predicted Label: Malware\nSample 5: True Label: Malware, Predicted Label: Malware\nSample 6: True Label: Malware, Predicted Label: Malware\nSample 7: True Label: DDoS, Predicted Label: DDoS\nSample 8: True Label: Malware, Predicted Label: Malware\nSample 9: True Label: Malware, Predicted Label: Malware\nSample 10: True Label: DDoS, Predicted Label: DDoS\nSample 11: True Label: DDoS, Predicted Label: DDoS\nSample 12: True Label: DDoS, Predicted Label: DDoS\nSample 13: True Label: System Failure, Predicted Label: System Failure\nSample 14: True Label: DDoS, Predicted Label: DDoS\nSample 15: True Label: DDoS, Predicted Label: DDoS\nNone\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"model.save(\"IT HACKATHON.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:18:32.695008Z","iopub.execute_input":"2025-03-15T10:18:32.695316Z","iopub.status.idle":"2025-03-15T10:18:32.756634Z","shell.execute_reply.started":"2025-03-15T10:18:32.695285Z","shell.execute_reply":"2025-03-15T10:18:32.755945Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import pickle\nfilename = \"IT HACKATHON.pkl\"\n\n# Save model\nwith open(filename, \"wb\") as file:\n    pickle.dump(model, file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:21:07.111136Z","iopub.execute_input":"2025-03-15T10:21:07.111458Z","iopub.status.idle":"2025-03-15T10:21:07.141299Z","shell.execute_reply.started":"2025-03-15T10:21:07.111423Z","shell.execute_reply":"2025-03-15T10:21:07.140690Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"model.save('/kaggle/working/IT HACKATHON.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T10:23:44.633896Z","iopub.execute_input":"2025-03-15T10:23:44.634202Z","iopub.status.idle":"2025-03-15T10:23:44.659906Z","shell.execute_reply.started":"2025-03-15T10:23:44.634179Z","shell.execute_reply":"2025-03-15T10:23:44.659252Z"}},"outputs":[],"execution_count":24}]}